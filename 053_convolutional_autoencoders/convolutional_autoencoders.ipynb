{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4106f36a-a473-4465-9c3c-702ebbb7d679",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Instead of learning filters in a CNN supervised, we can also learn the filters in a CNN unsupervised.\n",
    "\n",
    "A work that already tried this out is:\n",
    "\n",
    "[\"Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction\"](https://people.idsia.ch/~ciresan/data/icann2011.pdf) by Jonathan Masci, Ueli Meier, Dan Ciresan, and Jurgen Schmidhuber. ICANN 2011.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b158d-ac8a-4b7c-a5aa-7c42f50eff77",
   "metadata": {},
   "source": [
    "# GPU check Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e33e95-a82a-4ea6-ac69-4fab96d2f23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f5a5b-102e-4077-8120-7ded1ec4fa22",
   "metadata": {},
   "source": [
    "# GPU check PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dcf336c-9047-427b-adfe-f040f7c40dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if a GPU is available and if not, fall back on CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"available device: {device}\")\n",
    "\n",
    "# Define a simple model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10)\n",
    ")\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(device)\n",
    "\n",
    "# Now any tensor you pass to the model will be automatically moved to the GPU\n",
    "input = torch.randn(1, 100).to(device)\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cae45-e09d-4001-adde-b67e2309f894",
   "metadata": {},
   "source": [
    "# Convolutional autoencoder with Keras\n",
    "\n",
    "Here is an example how to learn filters with autoencoders in TensorFlow / Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47957bb9-c30c-44f9-bbe2-be92993fa165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, UpSampling2D, Input\n",
    "\n",
    "# 1. load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10) # generate one-hot-encoding vectors\n",
    "y_test = keras.utils.to_categorical(y_test, 10)   # generate one-hot-encoding vectors\n",
    "\n",
    "\n",
    "# 2. define and train the autoencoder\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()\n",
    "\n",
    "# note the fit(x_train, x_train)!\n",
    "autoencoder.fit(x_train, x_train, epochs=5, batch_size=128, validation_data=(x_test, x_test))\n",
    "\n",
    "\n",
    "# 3. define the CNN using the trained autoencoder weights\n",
    "cnn = Sequential()\n",
    "\n",
    "# here we use the autoencoder learned weights from the\n",
    "# encoder part of the above autoencoder\n",
    "cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), weights=autoencoder.layers[1].get_weights()))\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "cnn.summary()\n",
    "\n",
    "# 4. train the CNN\n",
    "cnn.fit(x_train, y_train, batch_size=128, epochs=5, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4decc-0944-4cf0-a996-85c04e3bceb3",
   "metadata": {},
   "source": [
    "# Convolutional autoencoders with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "260b4454-6a2a-4b58-840a-17b69c851b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the CNN...\n",
      "Epoch: 0, Loss: 0.3354\n",
      "Epoch: 1, Loss: 0.1316\n",
      "Epoch: 2, Loss: 0.0517\n",
      "Epoch: 3, Loss: 0.1358\n",
      "Epoch: 4, Loss: 0.0799\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 1. check if a GPU is available and if not, fall back on CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. load MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "# 3. define the autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "autoencoder = Autoencoder().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "\n",
    "# 4. train the autoencoder?\n",
    "if True:\n",
    "    print(\"\\nTraining autoencoder...\")\n",
    "    for epoch in range(5):\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = autoencoder(data)\n",
    "            loss = criterion(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch: {}, Loss: {:.4f}'.format(epoch, float(loss)))\n",
    "\n",
    "    \n",
    "# 5. define the CNN using the trained autoencoder weights\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = pretrained.encoder\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten(),            \n",
    "            nn.Linear(64*7*7, 128),  # Changed the input size here\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN(autoencoder).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters())\n",
    "\n",
    "# 6. train the CNN\n",
    "print(\"\\nTraining the CNN...\")\n",
    "for epoch in range(5):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = cnn(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch: {}, Loss: {:.4f}'.format(epoch, float(loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "030d517e-f12d-4c63-914a-66285ff89d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=3136, out_features=128, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68da015-33b0-4451-94a4-d118080efe60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
